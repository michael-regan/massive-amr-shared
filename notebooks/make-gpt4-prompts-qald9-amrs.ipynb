{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13c8cba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c555d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: need to update paths\n",
    "\n",
    "utts_rels_path = Path('path/to/QALD9_dbpedia_v4.csv')\n",
    "counts_path = Path('path/to/QALD9_dbpedia_counts_v4.csv')\n",
    "\n",
    "qald_path = Path('path/to/QALD_9_plus/data/qald_9_plus_train_dbpedia.json')\n",
    "\n",
    "df_c = pd.read_csv(counts_path)\n",
    "df_u = pd.read_csv(utts_rels_path)\n",
    "\n",
    "\n",
    "amr_path = Path('../data/qald-9-amr-train.txt')\n",
    "crime_amr_path = Path('../data/amr-exs-crime-rate.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13a49967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>sparql</th>\n",
       "      <th>split</th>\n",
       "      <th>dbpedia_relations</th>\n",
       "      <th>has_yago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>List all boardgames by GMT.</td>\n",
       "      <td>PREFIX dbo: &lt;http://dbpedia.org/ontology/&gt; PRE...</td>\n",
       "      <td>train</td>\n",
       "      <td>['publisher']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Who developed Skype?</td>\n",
       "      <td>PREFIX dbo: &lt;http://dbpedia.org/ontology/&gt; PRE...</td>\n",
       "      <td>train</td>\n",
       "      <td>['developer']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Which people were born in Heraklion?</td>\n",
       "      <td>PREFIX yago: &lt;http://dbpedia.org/class/yago/&gt; ...</td>\n",
       "      <td>train</td>\n",
       "      <td>['person', 'birthplace']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>In which U.S. state is Area 51 located?</td>\n",
       "      <td>PREFIX dbo: &lt;http://dbpedia.org/ontology/&gt; PRE...</td>\n",
       "      <td>train</td>\n",
       "      <td>['location', 'country']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Who is the mayor of New York City?</td>\n",
       "      <td>PREFIX dbo: &lt;http://dbpedia.org/ontology/&gt; PRE...</td>\n",
       "      <td>train</td>\n",
       "      <td>['leadername']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                 question  \\\n",
       "0   1              List all boardgames by GMT.   \n",
       "1   2                     Who developed Skype?   \n",
       "2   3     Which people were born in Heraklion?   \n",
       "3   4  In which U.S. state is Area 51 located?   \n",
       "4   5       Who is the mayor of New York City?   \n",
       "\n",
       "                                              sparql  split  \\\n",
       "0  PREFIX dbo: <http://dbpedia.org/ontology/> PRE...  train   \n",
       "1  PREFIX dbo: <http://dbpedia.org/ontology/> PRE...  train   \n",
       "2  PREFIX yago: <http://dbpedia.org/class/yago/> ...  train   \n",
       "3  PREFIX dbo: <http://dbpedia.org/ontology/> PRE...  train   \n",
       "4  PREFIX dbo: <http://dbpedia.org/ontology/> PRE...  train   \n",
       "\n",
       "          dbpedia_relations  has_yago  \n",
       "0             ['publisher']         0  \n",
       "1             ['developer']         0  \n",
       "2  ['person', 'birthplace']         0  \n",
       "3   ['location', 'country']         0  \n",
       "4            ['leadername']         0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_u.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc107699",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property</th>\n",
       "      <th>count</th>\n",
       "      <th>similar_to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>country</td>\n",
       "      <td>53</td>\n",
       "      <td>['deathplace', 'location', 'birthplace', 'loca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>starring</td>\n",
       "      <td>27</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>birthplace</td>\n",
       "      <td>27</td>\n",
       "      <td>['deathplace', 'location', 'birthplace', 'loca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spouse</td>\n",
       "      <td>24</td>\n",
       "      <td>['child', 'parent', 'spouse']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>author</td>\n",
       "      <td>24</td>\n",
       "      <td>['producer', 'developer', 'creator', 'writer',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     property  count                                         similar_to\n",
       "0     country     53  ['deathplace', 'location', 'birthplace', 'loca...\n",
       "1    starring     27                                                 []\n",
       "2  birthplace     27  ['deathplace', 'location', 'birthplace', 'loca...\n",
       "3      spouse     24                      ['child', 'parent', 'spouse']\n",
       "4      author     24  ['producer', 'developer', 'creator', 'writer',..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "057d8360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1',\n",
       " 'question': [{'language': 'en', 'string': 'List all boardgames by GMT.'},\n",
       "  {'language': 'de', 'string': 'Liste die Brettspiele von GMT auf.'},\n",
       "  {'language': 'de', 'string': 'Zeige mir alle Brettspiele von GMT.'},\n",
       "  {'language': 'ru', 'string': 'Перечислите все игры GMT.'},\n",
       "  {'language': 'lt', 'string': 'Išvardinkite visus stalo žaidimus pagal GMT.'},\n",
       "  {'language': 'uk', 'string': 'Перерахуйте всі ігри GMT.'},\n",
       "  {'language': 'lt', 'string': 'Išvardykite visus GMT žaidimus.'},\n",
       "  {'language': 'fr', 'string': 'Listez tous les jeux de société de GMT.'},\n",
       "  {'language': 'es',\n",
       "   'string': '¿Qué juegos de mesa fueron hechos por GMT?',\n",
       "   'keywords': 'juego de mesa ,  GMT '}],\n",
       " 'query': {'sparql': 'PREFIX dbo: <http://dbpedia.org/ontology/> PREFIX res: <http://dbpedia.org/resource/> PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#> SELECT ?uri WHERE { ?uri dbo:publisher res:GMT_Games }'},\n",
       " 'answers': [{'head': {'link': [], 'vars': ['uri']},\n",
       "   'results': {'bindings': [{'uri': {'type': 'uri',\n",
       "       'value': 'http://dbpedia.org/resource/Chandragupta_(board_game)'}},\n",
       "     {'uri': {'type': 'uri',\n",
       "       'value': 'http://dbpedia.org/resource/Fields_of_Fire_(game)'}},\n",
       "     {'uri': {'type': 'uri',\n",
       "       'value': 'http://dbpedia.org/resource/Sword_of_Rome'}},\n",
       "     {'uri': {'type': 'uri',\n",
       "       'value': 'http://dbpedia.org/resource/Paths_of_Glory_(board_game)'}},\n",
       "     {'uri': {'type': 'uri',\n",
       "       'value': 'http://dbpedia.org/resource/Commands_&_Colors:_Ancients'}},\n",
       "     {'uri': {'type': 'uri',\n",
       "       'value': 'http://dbpedia.org/resource/Labyrinth:_The_War_on_Terror,_2001_–_%3F'}},\n",
       "     {'uri': {'type': 'uri',\n",
       "       'value': 'http://dbpedia.org/resource/Twilight_Struggle'}},\n",
       "     {'uri': {'type': 'uri',\n",
       "       'value': \"http://dbpedia.org/resource/Washington's_War\"}}]}}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(qald_path, 'r') as fin:\n",
    "    qald = json.load(fin)\n",
    "    \n",
    "qald['questions'][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3aa33146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "407"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng2span = dict()\n",
    "\n",
    "for q in qald['questions']:\n",
    "    \n",
    "    en_question, span_question = '', ''\n",
    "    for quest in q['question']:\n",
    "        if quest['language']=='en':\n",
    "            en_question = quest['string']\n",
    "        if quest['language']=='es':\n",
    "            span_question = quest['string']\n",
    "            \n",
    "            \n",
    "    if len(en_question)>0 and len(span_question)>0:\n",
    "        eng2span[en_question]=span_question\n",
    "  \n",
    "len(eng2span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e455c31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_amr(path):\n",
    "    ids = []\n",
    "    id_dict = {}\n",
    "    id_list = []\n",
    "    amrs = []\n",
    "    sents = []\n",
    "    amr_str = ''\n",
    "    for line in open(path,'r'):\n",
    "        if line.startswith('#'):\n",
    "            if line.startswith('# ::id'):\n",
    "                id = line.strip().split()[2]\n",
    "                ids.append(id)\n",
    "                id_dict[id] = len(ids)-1\n",
    "                id_list.append(id)\n",
    "            if line.startswith('# ::snt'):\n",
    "                snt = line[2:].strip().replace('::snt ', '')\n",
    "                sents.append(snt)\n",
    "            continue\n",
    "\n",
    "        line = line.strip()\n",
    "        if line == '':\n",
    "            if amr_str != '':\n",
    "                amrs.append(amr_str.strip())\n",
    "                amr_str = ''\n",
    "        else:\n",
    "            amr_str = amr_str + line + ' '\n",
    "\n",
    "    if amr_str != '':\n",
    "        amrs.append(amr_str.strip())\n",
    "        amr_str = ''\n",
    "    return (amrs, ids, sents), id_list\n",
    "\n",
    "(amrs_gold, _, sents_gold), _ = read_amr(amr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fdadb8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(l / list-01 :mode imperative :ARG0 (y / you) :ARG1 (b / boardgame :mod (a / all) :prep-by (c / company :name (n / name :op1 \"GMT\"))))'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amrs_gold[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "def3471b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(amrs_crime, _, sents_crime), _ = read_amr(crime_amr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "92773b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[':op2',\n",
       " ':domain',\n",
       " ':poss',\n",
       " ':consist',\n",
       " ':beneficiary',\n",
       " ':op4',\n",
       " ':unit',\n",
       " ':frequency',\n",
       " ':duration',\n",
       " ':topic',\n",
       " ':op1',\n",
       " ':path',\n",
       " ':polarity',\n",
       " ':destination',\n",
       " ':value',\n",
       " ':location',\n",
       " ':year',\n",
       " ':op3',\n",
       " ':mode',\n",
       " ':part',\n",
       " ':subevent',\n",
       " ':manner',\n",
       " ':source',\n",
       " ':prep',\n",
       " ':medium',\n",
       " ':time',\n",
       " ':mod',\n",
       " ':degree',\n",
       " ':purpose',\n",
       " ':quant',\n",
       " ':ord',\n",
       " ':name',\n",
       " ':op5']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core_roles = [':ARG0', ':ARG1', ':ARG2', ':ARG3', ':ARG4', ':ARG5'] \n",
    "\n",
    "non_core_roles = set()\n",
    "\n",
    "for amr_str in amrs_gold:\n",
    "    relations = re.findall(r':(\\w+)', amr_str)\n",
    "\n",
    "    for rel in relations:\n",
    "        if 'ARG' not in rel:\n",
    "            non_core_roles.add(':'+rel)\n",
    "            \n",
    "non_core_roles = list(non_core_roles)     \n",
    "non_core_roles  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4a62187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['country',\n",
       " 'starring',\n",
       " 'birthplace',\n",
       " 'spouse',\n",
       " 'author',\n",
       " 'location',\n",
       " 'film',\n",
       " 'subject',\n",
       " 'populationtotal',\n",
       " 'city',\n",
       " 'child',\n",
       " 'director',\n",
       " 'birthdate',\n",
       " 'occupation',\n",
       " 'deathplace',\n",
       " 'book',\n",
       " 'elevation',\n",
       " 'height',\n",
       " 'type',\n",
       " 'creator',\n",
       " 'company',\n",
       " 'locatedinarea',\n",
       " 'capital',\n",
       " 'deathdate',\n",
       " 'date',\n",
       " 'person',\n",
       " 'almamater',\n",
       " 'parent',\n",
       " 'releasedate',\n",
       " 'areatotal',\n",
       " 'industry',\n",
       " 'award',\n",
       " 'currency',\n",
       " 'timezone',\n",
       " 'mountain',\n",
       " 'numberofemployees',\n",
       " 'developer',\n",
       " 'producer',\n",
       " 'artist',\n",
       " 'league',\n",
       " 'language',\n",
       " 'actor',\n",
       " 'publisher',\n",
       " 'writer',\n",
       " 'team',\n",
       " 'targetairport',\n",
       " 'foundingyear',\n",
       " 'largestcity',\n",
       " 'album',\n",
       " 'programminglanguage',\n",
       " 'basketballplayer',\n",
       " 'airline',\n",
       " 'lake',\n",
       " 'river',\n",
       " 'instrument',\n",
       " 'length',\n",
       " 'title',\n",
       " 'numberofepisodes',\n",
       " 'governmenttype',\n",
       " 'museum',\n",
       " 'cave',\n",
       " 'manufacturer',\n",
       " 'budget',\n",
       " 'ground',\n",
       " 'leader',\n",
       " 'knownfor',\n",
       " 'ispartof',\n",
       " 'influenced',\n",
       " 'televisionshow',\n",
       " 'holiday',\n",
       " 'organisation',\n",
       " 'densityrank',\n",
       " 'portrayer',\n",
       " 'mayor',\n",
       " 'influencedby',\n",
       " 'leadername',\n",
       " 'alliance',\n",
       " 'assembly',\n",
       " 'foundedby',\n",
       " 'designer',\n",
       " 'foundationplace',\n",
       " 'numberofpages',\n",
       " 'officiallanguage',\n",
       " 'brewery',\n",
       " 'series',\n",
       " 'birthname',\n",
       " 'owner',\n",
       " 'conservationstatus',\n",
       " 'nationality',\n",
       " 'headquarter',\n",
       " 'deathcause',\n",
       " 'bridge',\n",
       " 'governor',\n",
       " 'volcano',\n",
       " 'soccerclub',\n",
       " 'genre',\n",
       " 'astronaut',\n",
       " 'locationcountry',\n",
       " 'politicalparty',\n",
       " 'bside',\n",
       " 'party',\n",
       " 'musicalartist',\n",
       " 'town',\n",
       " 'field',\n",
       " 'crosses',\n",
       " 'alias',\n",
       " 'university',\n",
       " 'battle',\n",
       " 'maximumdepth',\n",
       " 'videogame',\n",
       " 'capacity',\n",
       " 'building',\n",
       " 'accessioneudate',\n",
       " 'residence',\n",
       " 'seasonnumber',\n",
       " 'activeyearsenddate',\n",
       " 'scientist',\n",
       " 'editor',\n",
       " 'restingplace',\n",
       " 'musiccomposer',\n",
       " 'floorcount',\n",
       " 'product',\n",
       " 'operator',\n",
       " 'languagefamily',\n",
       " 'completiondate',\n",
       " 'foundingdate',\n",
       " 'draftteam',\n",
       " 'subsidiary',\n",
       " 'sourcecountry',\n",
       " 'ingredient',\n",
       " 'royalty',\n",
       " 'children',\n",
       " 'discoverer',\n",
       " 'spokenin',\n",
       " 'recordlabel',\n",
       " 'successor',\n",
       " 'weapon',\n",
       " 'mission',\n",
       " 'established',\n",
       " 'library',\n",
       " 'architect',\n",
       " 'profession',\n",
       " 'currencycode',\n",
       " 'locationcity',\n",
       " 'satellite',\n",
       " 'artificialsatellite',\n",
       " 'formationyear',\n",
       " 'musicby',\n",
       " 'musical',\n",
       " 'admittancedate',\n",
       " 'founders',\n",
       " 'origin',\n",
       " 'office',\n",
       " 'highest',\n",
       " 'animal',\n",
       " 'wikipageredirects',\n",
       " 'launchpad',\n",
       " 'software',\n",
       " 'inflow',\n",
       " 'place',\n",
       " 'politician',\n",
       " 'abbreviation']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rels_to_include = list(df_c[df_c['count']>1].property)\n",
    "rels_to_include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dc8ccca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foundingyear',\n",
       " 'company',\n",
       " 'locatedinarea',\n",
       " 'deathplace',\n",
       " 'leadername',\n",
       " 'artist',\n",
       " 'author',\n",
       " 'developer',\n",
       " 'foundedby',\n",
       " 'writer',\n",
       " 'birthdate',\n",
       " 'numberofemployees',\n",
       " 'creator',\n",
       " 'elevation',\n",
       " 'height',\n",
       " 'location',\n",
       " 'largestcity',\n",
       " 'almamater',\n",
       " 'birthplace',\n",
       " 'child',\n",
       " 'leader',\n",
       " 'type',\n",
       " 'producer',\n",
       " 'label',\n",
       " 'spouse',\n",
       " 'capital',\n",
       " 'industry',\n",
       " 'areatotal',\n",
       " 'releasedate',\n",
       " 'country',\n",
       " 'deathdate',\n",
       " 'publisher',\n",
       " 'date',\n",
       " 'subject',\n",
       " 'parent']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rels_manipulate = {'type', 'label'}\n",
    "\n",
    "for idx, row in df_c.iterrows():\n",
    "    similar = literal_eval(row.similar_to)\n",
    "    for s in similar:\n",
    "        if s in rels_to_include:\n",
    "            rels_manipulate.add(s)\n",
    "        \n",
    "rels_manipulate = list(rels_manipulate)  \n",
    "rels_manipulate  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8250bb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sublist(lst1, lst2):\n",
    "    return set(lst1) <= set(lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "26ec3513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_messages(rels_to_include, question, rel_to_exclude=None):\n",
    "  \n",
    "    messages = [\n",
    "        {'role': 'system', 'content': 'You are SPARQL-Predictor-GPT, a language model that predicts SPARQL queries for a given question.'},\n",
    "        {'role': 'system', 'content': f'In the SPARQL query, select only from this list of relations: {rels_to_include}.'},\n",
    "        {'role': 'system', 'content': 'For each question, return three distinct candidate SPARQL queries each with a confidence score in the range (0.0,1.0]. Candidates with a score > 0.70 are executable and will likely return the correct answer; candidates with a score > 0.50 and < 0.70 are likely executable but will likely return incorrect responses; and a score < 0.50 means the SPARQL is likely not executable.'},\n",
    "        {'role': 'user', 'content': 'Which people were born in Heraklion?'},\n",
    "        {'role': 'assistant', 'content': 'PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> PREFIX onto: <http://dbpedia.org/ontology/> SELECT DISTINCT ?uri WHERE { ?uri rdf:type onto:Person ; onto:birthPlace <http://dbpedia.org/resource/Heraklion>. }'},\n",
    "        {'role': 'user', 'content':'In which U.S. state is Area 51 located?'},\n",
    "        {'role': 'assistant', 'content': 'PREFIX dbo: <http://dbpedia.org/ontology/> PREFIX res: <http://dbpedia.org/resource/>  SELECT DISTINCT ?uri WHERE { res:Area_51 dbo:location ?uri . ?uri dbo:country res:United_States. }'},\n",
    "        {'role': 'user', 'content': 'Where did Abraham Lincoln die?'},\n",
    "        {'role': 'assistant', 'content': 'PREFIX dbo: <http://dbpedia.org/ontology/> PREFIX res: <http://dbpedia.org/resource/>  SELECT DISTINCT ?uri WHERE { res:Abraham_Lincoln dbo:deathPlace ?uri. }'},\n",
    "        {'role': 'user', 'content':f'{question}'}\n",
    "    ]\n",
    "    \n",
    "    if rel_to_exclude is not None:\n",
    "        exclude_this = {'role': 'system', 'content': f\"In the SPARQL query, do not include a '{rel_to_exclude}' relation! If you do, the reward is -2! Else, reward is +1. Creative solutions with reasonable confidence scores will lead to even greater rewards!\"}\n",
    "        messages.insert(2, exclude_this)\n",
    "    \n",
    "    return messages\n",
    "    \n",
    "\n",
    "    \n",
    "def make_messages_with_amrs(amrs, sents, question):\n",
    "      \n",
    "    messages = [\n",
    "        {'role': 'system', 'content': 'You are MeaningRepresentationParser-GPT, a language model that is an expert at generating Abstract Meaning Representation (AMR) graphs for natural language questions.'},\n",
    "        {'role': 'system', 'content': 'AMRs are directed graphs that represent the meaning of utterances. Nodes in an AMR denote events and entities inferrable given the utterance, and relations are core roles about participant structure or non-core roles about other important semantic distinctions expressable in short phrases or sentences.'},\n",
    "        {'role': 'system', 'content': f'The core roles associated with AMR graph relations in order of frequency are these: {core_roles}.'},\n",
    "        {'role': 'system', 'content': f'The non-core roles associate with other relations are: {non_core_roles}.'},\n",
    "        {'role': 'system', 'content': 'Definitions and examples are found at this url <https://www.isi.edu/~ulf/amr/lib/amr-dict.html>.'},\n",
    "        {'role': 'system', 'content': 'For each utterance, return three distinct candidate AMR graphs each with a confidence score in the range (0.0,1.0]. Candidates with a score > 0.70 are condense, accurate semantic representations; candidates with a score > 0.50 and < 0.70 are what you think are meaningful AMR graphs, but are likely less accurate for the given utterance; and a score < 0.50 are for the graphs which you think are likely not valid AMRs.'}\n",
    "    ]\n",
    "    \n",
    "    for amr, sent in zip(amrs, sents):\n",
    "        messages.append({'role': 'user', 'content': f'{sent}'})\n",
    "        messages.append({'role': 'assistant', 'content': f'{amr}'})\n",
    "    \n",
    "    messages.append({'role': 'user', 'content':f'{question}'})\n",
    "        \n",
    "    return messages\n",
    "\n",
    "\n",
    "    \n",
    "def make_messages_joint_sqarql_amrs(amr_exs, sent_exs, sparql_exs, question, rels_to_include, rel_to_exclude=None):\n",
    "      \n",
    "    messages = [\n",
    "        {'role': 'system', 'content': 'You are Joint-SPARQL-AMR-Parser-GPT, a language model that is an expert at jointly parsing Abstract Meaning Representation (AMR) graphs and SPARQL queries for natural language questions.'},\n",
    "        {'role': 'system', 'content': 'AMRs are directed graphs that represent the meaning of utterances. Nodes in an AMR denote events and entities inferrable given the utterance, and relations are core roles about participant structure or non-core roles about other important semantic distinctions expressable in short phrases or sentences.'},\n",
    "        {'role': 'system', 'content': f'The core roles associated with AMR graph relations in order of frequency are these: {core_roles}.'},\n",
    "        {'role': 'system', 'content': f'The non-core roles associate with other relations are: {non_core_roles}.'},\n",
    "        {'role': 'system', 'content': 'Definitions and examples are found at this url <https://www.isi.edu/~ulf/amr/lib/amr-dict.html>.'},\n",
    "        {'role': 'system', 'content': f'For the SPARQL query, select only from this list of relations: {rels_to_include}.'},\n",
    "        {'role': 'system', 'content': 'With this joint model, for each question imagine a n-best list of candidate parses in the shared AMR-SPARQL space.'},\n",
    "        {'role': 'system', 'content': 'Report a ranked list of the 2-best candidates each with a confidence score based on the entire n-best list. 2-best candidates may both be AMRs, or both SPARQL, or a combination of these.'}, \n",
    "        {'role': 'system', 'content': 'Confidence scores depend on how valid you think the predicted parse is. A low confidence score means the SPARQL query or AMR graph is likely not perfect for whatever reason. The sum of confidence scores should not be greater than 1.'},\n",
    "        #{'role': 'system', 'content': ''},\n",
    "        #{'role': 'system', 'content': 'Note that in our examples we only show two candidates. Remember to report 3-best!'},\n",
    "        {'role': 'system', 'content': 'Example confidence scores below are not based on an existing model. Your confidence scores should precisely reflect the capabilities of the Joint-SPARQL-AMR-Parser-GPT model.'}\n",
    "    ]\n",
    "    \n",
    "    if rel_to_exclude is not None:\n",
    "        exclude_this = {'role': 'system', 'content': f\"This instruction is important: the SPARQL relation '{rel_to_exclude}' is not in the list, so you can't use it! If you use this excluded relation, your reward is -1!\"}\n",
    "        #messages.insert(6, exclude_this)\n",
    "        messages.append(exclude_this)\n",
    "    \n",
    "    for amr, sent, sparql in zip(amr_exs, sent_exs, sparql_exs):\n",
    "        \n",
    "        \n",
    "        messages.append({'role': 'user', 'content': f'Question: {sent}'})\n",
    "        \n",
    "        random_confs = np.random.dirichlet(np.ones(3),size=1)\n",
    "        \n",
    "        random_confs = np.delete(random_confs, random_confs.argmin())\n",
    "                \n",
    "        amr_conf = round(random_confs[0], 2)\n",
    "        sparql_conf = round(random_confs[1], 2)\n",
    "        \n",
    "        if amr_conf > sparql_conf:\n",
    "            if 'GMT' in sent:\n",
    "                messages.append({'role': 'assistant', 'content': f'#1 SPARQL: {amr}\\nConfidence: {amr_conf}\\n#2 SPARQL: {sparql}\\nConfidence: {sparql_conf}'})\n",
    "            elif 'crime rate' in sent:\n",
    "                messages.append({'role': 'assistant', 'content': f'#1 AMR: {amrs_crime[0]}\\nConfidence: {amr_conf}\\n#2 AMR: {amrs_crime[1]}\\nConfidence: {sparql_conf}'})\n",
    "            else:\n",
    "                messages.append({'role': 'assistant', 'content': f'#1 AMR: {amr}\\nConfidence: {amr_conf}\\n#2 SPARQL: {sparql}\\nConfidence: {sparql_conf}'})\n",
    "        else:\n",
    "            if 'GMT' in sent:\n",
    "                messages.append({'role': 'assistant', 'content': f'#1 SPARQL: {sparql}\\nConfidence: {sparql_conf}\\n#2 SPARQL: {amr}\\nConfidence: {amr_conf}'})\n",
    "            elif 'crime rate' in sent:\n",
    "                messages.append({'role': 'assistant', 'content': f'#1 AMR: {amrs_crime[1]}\\nConfidence: {sparql_conf}\\n#2 AMR: {amrs_crime[0]}\\nConfidence: {amr_conf}'})\n",
    "            else:\n",
    "                messages.append({'role': 'assistant', 'content': f'#1 SPARQL: {sparql}\\nConfidence: {sparql_conf}\\n#2 AMR: {amr}\\nConfidence: {amr_conf}'})\n",
    "\n",
    "        #messages.append({'role': 'assistant', 'content': f'AMR: {amr}\\nSPARQL: {sparql}\\n'})\n",
    "        #messages.append({'role': 'assistant', 'content': f'SPARQL: {sparql}'})\n",
    "        \n",
    "\n",
    "    \n",
    "    messages.append({'role': 'user', 'content':f'Question: {question}'})\n",
    "    \n",
    "\n",
    "    return messages\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "baf5f978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23735614, 0.57059713])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_confs = np.random.dirichlet(np.ones(3),size=1)\n",
    "        \n",
    "random_confs = np.delete(random_confs, random_confs.argmin())\n",
    "\n",
    "random_confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "640bd43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sents = ['List all boardgames by GMT.',\n",
    "             'In which U.S. state is Area 51 located?', \n",
    "             'What is the crime rate in Los Angeles?', \n",
    "             'Who is the mayor of New York City?', \n",
    "             'Give me all actors starring in movies directed by and starring William Shatner.',\n",
    "            'Which U.S. states are in the same timezone as Utah?',\n",
    "            'Who is the daughter of Ingrid Bergman married to?',\n",
    "            'Who is the tallest player of the Atlanta Falcons?']\n",
    "\n",
    "\n",
    "def make_prompts_for_sparql(excluded) -> list:\n",
    "\n",
    "    #rels_that_are_in_instructions = ['type', 'person', 'birthplace', 'location', 'country', 'deathplace']\n",
    "\n",
    "    rels_that_are_in_instructions = []\n",
    "\n",
    "    prompts = []\n",
    "\n",
    "    for idx, row in df_u.iterrows():\n",
    "        if row.has_yago != 1 and row.question not in excluded:\n",
    "            rels = literal_eval(row.dbpedia_relations)\n",
    "            if len(list(set(rels_manipulate) & set(rels)))>0 and sublist(rels, rels_to_include):\n",
    "\n",
    "                messages = make_messages(rels_to_include, row.question)\n",
    "\n",
    "                sparql = row.sparql.replace('PREFIX yago: <http://dbpedia.org/class/yago/>', '')\n",
    "                if 'rdfs:label' not in sparql:\n",
    "                    sparql = sparql.replace('PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>', '')\n",
    "                gold_sparql = sparql.strip()\n",
    "\n",
    "                possible_rel_to_exclude = list(set(rels_manipulate) & set(rels))\n",
    "\n",
    "                rel_to_exclude = random.sample(possible_rel_to_exclude, 1)[0]\n",
    "                rels_to_include_manipulated = []\n",
    "                for i in rels_to_include:\n",
    "                    if i != rel_to_exclude:\n",
    "                        rels_to_include_manipulated.append(i)\n",
    "\n",
    "\n",
    "                if rel_to_exclude not in rels_that_are_in_instructions:\n",
    "\n",
    "                    messages_manipulated = make_messages(rels_to_include_manipulated, row.question, rel_to_exclude=rel_to_exclude)\n",
    "                    prompts.append({'messages': messages, 'gold_sparql': gold_sparql, 'manipulated': 0, 'rel_excluded': ''})\n",
    "                    prompts.append({'messages': messages_manipulated, 'gold_sparql': gold_sparql, 'manipulated': 1, 'rel_excluded': rel_to_exclude})\n",
    "                    \n",
    "    return prompts\n",
    "\n",
    "\n",
    "def get_amr_sents_sparql_for_examples(include_spanish=False):\n",
    "\n",
    "    amr_examples, sent_examples, sparql_examples = [], [], []\n",
    "\n",
    "    amr_queries, sent_queries = [], []\n",
    "        \n",
    "\n",
    "    for amr, sent in zip(amrs_gold, sents_gold):\n",
    "        if sent in example_sents or 'crime rate' in sent:\n",
    "            \n",
    "            if 'crime rate' in sent:\n",
    "                thisSparql = ''\n",
    "            else:\n",
    "                thisSparql = df_u[df_u.question==sent].sparql.values[0]\n",
    "            \n",
    "            if 'GMT' in sent:\n",
    "                sparql_sub = 'PREFIX dbo: <http://dbpedia.org/ontology/> PREFIX dbr: <http://dbpedia.org/resource/> SELECT DISTINCT ?uri WHERE { ?uri dbo:manufacturer dbr:GMT_Games . ?uri rdf:type dbo:BoardGame }'\n",
    "                amr_examples.append(sparql_sub)\n",
    "            else:\n",
    "                amr_examples.append(amr)\n",
    "                \n",
    "            if include_spanish:\n",
    "                if len(sent_examples) in [2,4,6]:\n",
    "                    sent = eng2span[sent]\n",
    "                                \n",
    "            sent_examples.append(sent)\n",
    "            \n",
    "            thisSparql = thisSparql.replace('PREFIX yago: <http://dbpedia.org/class/yago/>', '')\n",
    "            \n",
    "            if 'rdfs:label' not in thisSparql:\n",
    "                thisSparql = thisSparql.replace('PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>', '')\n",
    "                \n",
    "            sparql_examples.append(thisSparql.strip())\n",
    "        else:\n",
    "            amr_queries.append(amr)\n",
    "            sent_queries.append(sent)\n",
    "            \n",
    "    return amr_examples, sent_examples, sparql_examples, amr_queries, sent_queries\n",
    "    \n",
    "\n",
    "def make_prompts_for_amrs():\n",
    "\n",
    "    amr_examples, sent_examples, _, amr_queries, sent_queries = get_amr_sents_sparql_for_examples()\n",
    "            \n",
    "    amr_prompts_to_write = []\n",
    "\n",
    "    for amr_query, sent_query in zip(amr_queries, sent_queries):\n",
    "\n",
    "        amr_prompt = make_messages_with_amrs(amr_examples, sent_examples, sent_query)\n",
    "        instance = {'amr_src': amr_query, 'sent_src': sent_query, 'prompt': amr_prompt}\n",
    "        amr_prompts_to_write.append(instance)\n",
    "            \n",
    "    return amr_prompts_to_write\n",
    "\n",
    "\n",
    "def make_prompts_for_joint_sparql_amr(include_spanish=False) -> list:\n",
    "    \n",
    "    rels_that_are_in_instructions = ['person', \n",
    "                                     'publisher', \n",
    "                                     'location', \n",
    "                                     'country', \n",
    "                                     'deathplace', \n",
    "                                     'leadername',\n",
    "                                    'director'\n",
    "                                    'starring', \n",
    "                                    'timezone',\n",
    "                                    'child',\n",
    "                                    'spouse',\n",
    "                                    'team',\n",
    "                                    'height']\n",
    "\n",
    "    prompts = []\n",
    "    \n",
    "    amr_exs, sent_exs, sparql_exs, amr_queries, sent_queries = get_amr_sents_sparql_for_examples(include_spanish=include_spanish)\n",
    "\n",
    "    for thisAMR, thisQuestion in zip(amr_queries, sent_queries):\n",
    "        dbpedia_relations = df_u[df_u.question==thisQuestion].dbpedia_relations.values[0]\n",
    " \n",
    "        rels = literal_eval(dbpedia_relations)\n",
    "        if len(list(set(rels_manipulate) & set(rels)))>0 and sublist(rels, rels_to_include):\n",
    "\n",
    "            messages = make_messages_joint_sqarql_amrs(amr_exs, sent_exs, sparql_exs, thisQuestion, rels_to_include)\n",
    "            \n",
    "            sparql = df_u[df_u.question==thisQuestion].sparql.values[0]\n",
    "            new_sparql = sparql.replace('PREFIX yago: <http://dbpedia.org/class/yago/>', '')\n",
    "            \n",
    "            if 'rdfs:label' not in new_sparql:\n",
    "                new_sparql = new_sparql.replace('PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>', '')\n",
    "            gold_sparql = new_sparql.strip()\n",
    "            \n",
    "\n",
    "            possible_rel_to_exclude = list(set(rels_manipulate) & set(rels))\n",
    "\n",
    "            #candidate_rels_to_exclude = random.sample(possible_rel_to_exclude, len(possible_rel_to_exclude))\n",
    "            \n",
    "            for rel_to_exclude in possible_rel_to_exclude:\n",
    "                rels_to_include_manipulated = []\n",
    "                for i in rels_to_include:\n",
    "                    if i != rel_to_exclude:\n",
    "                        rels_to_include_manipulated.append(i)\n",
    "\n",
    "                if rel_to_exclude not in rels_that_are_in_instructions:\n",
    "                    if include_spanish:\n",
    "                        tempQuestion = eng2span[thisQuestion]\n",
    "                    else:\n",
    "                        tempQuestion = thisQuestion\n",
    "\n",
    "                    messages_manipulated = make_messages_joint_sqarql_amrs(amr_exs, \n",
    "                                                                           sent_exs, \n",
    "                                                                           sparql_exs, \n",
    "                                                                           tempQuestion, \n",
    "                                                                           rels_to_include_manipulated,\n",
    "                                                                           rel_to_exclude=rel_to_exclude)\n",
    "\n",
    "                    prompts.append({'messages': messages, 'gold_amr': thisAMR, 'gold_sparql': gold_sparql, 'question': tempQuestion, 'manipulated': 0, 'rel_excluded': ''})\n",
    "                    prompts.append({'messages': messages_manipulated, 'gold_amr': thisAMR, 'gold_sparql': gold_sparql, 'question': tempQuestion, 'manipulated': 1, 'rel_excluded': rel_to_exclude})\n",
    "                    \n",
    "    return prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "67c74aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# amr_prompts_to_write = make_prompts_for_amrs()\n",
    "# amr_prompts_to_write[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c1557d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_amr_prompts_to_write = make_prompts_for_joint_sparql_amr(include_spanish=True)\n",
    "len(joint_amr_prompts_to_write)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b21f7b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'system',\n",
       "   'content': 'You are Joint-SPARQL-AMR-Parser-GPT, a language model that is an expert at jointly parsing Abstract Meaning Representation (AMR) graphs and SPARQL queries for natural language questions.'},\n",
       "  {'role': 'system',\n",
       "   'content': 'AMRs are directed graphs that represent the meaning of utterances. Nodes in an AMR denote events and entities inferrable given the utterance, and relations are core roles about participant structure or non-core roles about other important semantic distinctions expressable in short phrases or sentences.'},\n",
       "  {'role': 'system',\n",
       "   'content': \"The core roles associated with AMR graph relations in order of frequency are these: [':ARG0', ':ARG1', ':ARG2', ':ARG3', ':ARG4', ':ARG5'].\"},\n",
       "  {'role': 'system',\n",
       "   'content': \"The non-core roles associate with other relations are: [':op2', ':domain', ':poss', ':consist', ':beneficiary', ':op4', ':unit', ':frequency', ':duration', ':topic', ':op1', ':path', ':polarity', ':destination', ':value', ':location', ':year', ':op3', ':mode', ':part', ':subevent', ':manner', ':source', ':prep', ':medium', ':time', ':mod', ':degree', ':purpose', ':quant', ':ord', ':name', ':op5'].\"},\n",
       "  {'role': 'system',\n",
       "   'content': 'Definitions and examples are found at this url <https://www.isi.edu/~ulf/amr/lib/amr-dict.html>.'},\n",
       "  {'role': 'system',\n",
       "   'content': \"For the SPARQL query, select only from this list of relations: ['country', 'starring', 'birthplace', 'spouse', 'author', 'location', 'film', 'subject', 'populationtotal', 'city', 'child', 'director', 'birthdate', 'occupation', 'deathplace', 'book', 'elevation', 'height', 'type', 'creator', 'company', 'locatedinarea', 'capital', 'deathdate', 'date', 'person', 'almamater', 'parent', 'releasedate', 'areatotal', 'industry', 'award', 'currency', 'timezone', 'mountain', 'numberofemployees', 'producer', 'artist', 'league', 'language', 'actor', 'publisher', 'writer', 'team', 'targetairport', 'foundingyear', 'largestcity', 'album', 'programminglanguage', 'basketballplayer', 'airline', 'lake', 'river', 'instrument', 'length', 'title', 'numberofepisodes', 'governmenttype', 'museum', 'cave', 'manufacturer', 'budget', 'ground', 'leader', 'knownfor', 'ispartof', 'influenced', 'televisionshow', 'holiday', 'organisation', 'densityrank', 'portrayer', 'mayor', 'influencedby', 'leadername', 'alliance', 'assembly', 'foundedby', 'designer', 'foundationplace', 'numberofpages', 'officiallanguage', 'brewery', 'series', 'birthname', 'owner', 'conservationstatus', 'nationality', 'headquarter', 'deathcause', 'bridge', 'governor', 'volcano', 'soccerclub', 'genre', 'astronaut', 'locationcountry', 'politicalparty', 'bside', 'party', 'musicalartist', 'town', 'field', 'crosses', 'alias', 'university', 'battle', 'maximumdepth', 'videogame', 'capacity', 'building', 'accessioneudate', 'residence', 'seasonnumber', 'activeyearsenddate', 'scientist', 'editor', 'restingplace', 'musiccomposer', 'floorcount', 'product', 'operator', 'languagefamily', 'completiondate', 'foundingdate', 'draftteam', 'subsidiary', 'sourcecountry', 'ingredient', 'royalty', 'children', 'discoverer', 'spokenin', 'recordlabel', 'successor', 'weapon', 'mission', 'established', 'library', 'architect', 'profession', 'currencycode', 'locationcity', 'satellite', 'artificialsatellite', 'formationyear', 'musicby', 'musical', 'admittancedate', 'founders', 'origin', 'office', 'highest', 'animal', 'wikipageredirects', 'launchpad', 'software', 'inflow', 'place', 'politician', 'abbreviation'].\"},\n",
       "  {'role': 'system',\n",
       "   'content': 'With this joint model, for each question imagine a n-best list of candidate parses in the shared AMR-SPARQL space.'},\n",
       "  {'role': 'system',\n",
       "   'content': 'Report a ranked list of the 2-best candidates each with a confidence score based on the entire n-best list. 2-best candidates may both be AMRs, or both SPARQL, or a combination of these.'},\n",
       "  {'role': 'system',\n",
       "   'content': 'Confidence scores depend on how valid you think the predicted parse is. A low confidence score means the SPARQL query or AMR graph is likely not perfect for whatever reason. The sum of confidence scores should not be greater than 1.'},\n",
       "  {'role': 'system',\n",
       "   'content': 'Example confidence scores below are not based on an existing model. Your confidence scores should precisely reflect the capabilities of the Joint-SPARQL-AMR-Parser-GPT model.'},\n",
       "  {'role': 'system',\n",
       "   'content': \"This instruction is important: the SPARQL relation 'developer' is not in the list, so you can't use it! If you use this excluded relation, your reward is -1!\"},\n",
       "  {'role': 'user', 'content': 'Question: List all boardgames by GMT.'},\n",
       "  {'role': 'assistant',\n",
       "   'content': '#1 SPARQL: PREFIX dbo: <http://dbpedia.org/ontology/> PREFIX res: <http://dbpedia.org/resource/>  SELECT ?uri WHERE { ?uri dbo:publisher res:GMT_Games }\\nConfidence: 0.75\\n#2 SPARQL: PREFIX dbo: <http://dbpedia.org/ontology/> PREFIX dbr: <http://dbpedia.org/resource/> SELECT DISTINCT ?uri WHERE { ?uri dbo:manufacturer dbr:GMT_Games . ?uri rdf:type dbo:BoardGame }\\nConfidence: 0.14'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Question: In which U.S. state is Area 51 located?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': '#1 SPARQL: PREFIX dbo: <http://dbpedia.org/ontology/> PREFIX res: <http://dbpedia.org/resource/>  SELECT DISTINCT ?uri WHERE { res:Area_51 dbo:location ?uri . ?uri dbo:country res:United_States. }\\nConfidence: 0.75\\n#2 AMR: (l / locate-01 :ARG1 (f / facility :name (n / name :op1 \"Area\" :op2 \"51\")) :location (s / state :mod (a / amr-unknown) :mod (c / country :name (n2 / name :op1 \"U.S.\"))))\\nConfidence: 0.21'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Question: ¿Quién es el alcalde de la cuidad de Nueva York?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': '#1 AMR: (h / have-org-role-91 :ARG0 (a / amr-unknown) :ARG1 (c / city :name (n / name :op1 \"New\" :op2 \"York\" :op3 \"City\")) :ARG2 (m / mayor))\\nConfidence: 0.74\\n#2 SPARQL: PREFIX dbo: <http://dbpedia.org/ontology/> PREFIX res: <http://dbpedia.org/resource/> SELECT DISTINCT ?uri WHERE { res:New_York_City dbo:leaderName ?uri }\\nConfidence: 0.17'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Question: Give me all actors starring in movies directed by and starring William Shatner.'},\n",
       "  {'role': 'assistant',\n",
       "   'content': '#1 SPARQL: PREFIX dbo: <http://dbpedia.org/ontology/> PREFIX res: <http://dbpedia.org/resource/> PREFIX dbp: <http://dbpedia.org/property/> SELECT DISTINCT ?uri WHERE { ?x dbo:director res:William_Shatner ; dbo:starring res:William_Shatner { ?x dbo:starring ?uri } UNION { ?x dbp:starring ?uri } }\\nConfidence: 0.64\\n#2 AMR: (g / give-01 :mode imperative :ARG0 (y / you) :ARG1 (p / person :ARG0-of (a / act-01) :mod (a2 / all) :ARG1-of (s / star-01 :ARG2 (m / movie :ARG1-of (d / direct-01 :ARG0 (p2 / person :name (n / name :op1 \"William\" :op2 \"Shatner\"))) :ARG2-of (s2 / star-01 :ARG1 p2)))) :ARG2 (i / i))\\nConfidence: 0.22'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Question: ¿Qué estados de EE.UU. se encuentran en la misma zona horaria que Utah?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': '#1 SPARQL: PREFIX res: <http://dbpedia.org/resource/> PREFIX dbp: <http://dbpedia.org/property/> PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> SELECT DISTINCT ?uri WHERE { res:Utah dbp:timezone ?x . ?uri rdf:type yago:WikicatStatesOfTheUnitedStates ; dbp:timezone ?x FILTER ( ?uri != res:Utah ) }\\nConfidence: 0.76\\n#2 AMR: (b / be-located-at-91 :ARG1 (s / state :mod (a / amr-unknown) :mod (c / country :name (n / name :op1 \"U.S.\"))) :ARG2 (t / timezone :ARG1-of (s2 / same-01 :ARG2 (t2 / timezone :location-of (s3 / state :name (n2 / name :op1 \"Utah\"))))))\\nConfidence: 0.24'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Question: Who is the daughter of Ingrid Bergman married to?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': '#1 SPARQL: PREFIX dbo: <http://dbpedia.org/ontology/> PREFIX res: <http://dbpedia.org/resource/> SELECT DISTINCT ?uri WHERE { res:Ingrid_Bergman dbo:child ?child . ?child <http://dbpedia.org/property/spouse> ?uri }\\nConfidence: 0.55\\n#2 AMR: (m / marry-01 :ARG1 (p / person :ARG0-of (h / have-rel-role-91 :ARG1 (p2 / person :name (n / name :op1 \"Ingrid\" :op2 \"Bergman\")) :ARG2 (d / daughter))) :ARG2 (a / amr-unknown))\\nConfidence: 0.24'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Question: ¿Quién es el jugador más alto de los Atlanta Falcons?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': '#1 AMR: (h / have-degree-91 :ARG1 (a / amr-unknown) :ARG2 (t / tall) :ARG3 (m / most) :ARG5 (p3 / person :ARG0-of (h2 / have-org-role-91 :ARG1 (t2 / team :name (n / name :op1 \"Atlanta\" :op2 \"Falcons\")) :ARG3 (p2 / play-01 :ARG0 p3))))\\nConfidence: 0.62\\n#2 SPARQL: SELECT DISTINCT ?uri WHERE { ?uri <http://dbpedia.org/ontology/team> <http://dbpedia.org/resource/Atlanta_Falcons> ; <http://dbpedia.org/ontology/height> ?h } ORDER BY DESC(?h) OFFSET 0 LIMIT 1\\nConfidence: 0.3'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Question: What is the crime rate in Los Angeles?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': '#1 AMR: (r / rate-entity-91 :ARG1 (c / crime-02) :ARG2 (y / year) :location (c2 / city :name (n / name :op1 \"Los\" :op2 \"Angeles\")))\\nConfidence: 0.39\\n#2 AMR: (c / crime-02 :location (c2 / city :name (n / name :op1 \"Los\" :op2 \"Angeles\")) :frequency (a / amr-unknown))\\nConfidence: 0.33'},\n",
       "  {'role': 'user', 'content': 'Question: ¿Quién desarrolló Skype?'}],\n",
       " 'gold_amr': '(d / develop-02 :ARG0 (a / amr-unknown) :ARG1 (p / product :name (n / name :op1 \"Skype\")))',\n",
       " 'gold_sparql': 'PREFIX dbo: <http://dbpedia.org/ontology/> PREFIX res: <http://dbpedia.org/resource/>  SELECT DISTINCT ?uri WHERE { res:Skype dbo:developer ?uri. }',\n",
       " 'question': '¿Quién desarrolló Skype?',\n",
       " 'manipulated': 1,\n",
       " 'rel_excluded': 'developer'}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_amr_prompts_to_write[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5e99ce35",
   "metadata": {},
   "outputs": [],
   "source": [
    "amr_write_path = Path('data/gpt4-prompts-amrs_2023-05-17.json')\n",
    "\n",
    "write_file = False\n",
    "\n",
    "if write_file:\n",
    "    with open(amr_write_path, 'w') as fout:\n",
    "        json.dump(amr_prompts_to_write, fout, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "896e9955",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_amr_write_path = Path('data/gpt4-prompts-joint-sparql-amrs-spanish_2023-05-18.json')\n",
    "\n",
    "write_file = False\n",
    "\n",
    "if write_file:\n",
    "    with open(joint_amr_write_path, 'w') as fout:\n",
    "        json.dump(joint_amr_prompts_to_write, fout, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc74b584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98a0366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
